{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from fastapi import FastAPI, Request, Response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate pandas to display float numbers using only 2 decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ETL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Extraction: start by retrieving the data from various csv files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.1 Create all the necessary dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_ratings = pd.read_csv(\"https://drive.google.com/u/0/uc?id=1BAMVkLqMrXJDYNaLC973Jcd_r77WCgQn&export=download\")\n",
    "df2_ratings = pd.read_csv(\"https://drive.google.com/u/0/uc?id=1Pc60nR9sxXfmPIsJRvfhqYYOO5zA3VsT&export=download\")\n",
    "df3_ratings = pd.read_csv(\"https://drive.google.com/u/0/uc?id=1tkMrm_--FZWps1uXMwEF3XT_T3PMVQlk&export=download\")\n",
    "df4_ratings = pd.read_csv(\"https://drive.google.com/u/0/uc?id=167GBJwlhh58mVK-mSyJacQA8SB5uup93&export=download\")\n",
    "df5_ratings = pd.read_csv(\"https://drive.google.com/u/0/uc?id=1w94ESSIUruinU_Pf--jkKk8B2-GDxRb6&export=download\")\n",
    "df6_ratings = pd.read_csv(\"https://drive.google.com/u/0/uc?id=1N9MqB9DNpdGMWiK_fGXRf3FrosCjR9ob&export=download\")\n",
    "df7_ratings = pd.read_csv(\"https://drive.google.com/u/0/uc?id=16ipx0P4WY3SoVFN2LbVst1N_5yr98OYA&export=download\")\n",
    "df8_ratings = pd.read_csv(\"https://drive.google.com/u/0/uc?id=1n8UpCl-qWXPvzrhmP7W9ISH9lyy-_K4V&export=download\")\n",
    "df_amazon   = pd.read_csv(\"https://drive.google.com/u/0/uc?id=1WAtbMW-d49_PPSQ6Kngq9NoD-dcOOiC9&export=download\")\n",
    "df_disney   = pd.read_csv(\"https://drive.google.com/u/0/uc?id=1Qn_Tv5vEmWg5PRqJkBqN_0SaSG0zFtuR&export=download\")\n",
    "df_hulu     = pd.read_csv(\"https://drive.google.com/u/0/uc?id=11FFXj7Dn22HjAnT3hk0XmTzav7jY9B0l&export=download\")\n",
    "df_netflix  = pd.read_csv(\"https://drive.google.com/u/0/uc?id=1cwzLeYjPIeJ5aJbyJO-F1QO5iHYIh6T2&export=download\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.2 Combine all the ratings datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.concat([df1_ratings, df2_ratings, df3_ratings, df4_ratings, \n",
    "                        df5_ratings, df6_ratings, df7_ratings, df8_ratings])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Transformation: basic EDA and data cleaning/preparation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _First group of datasets  (ratings 1 - 8)_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.1 Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId       0\n",
       "rating       0\n",
       "timestamp    0\n",
       "movieId      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.2 Checking and dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.duplicated().sum()\n",
    "df_ratings.drop_duplicates(inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.3 Checking data types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId         int64\n",
       "rating       float64\n",
       "timestamp      int64\n",
       "movieId       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.4 Create a new column called date with a proper date format. I will NOT drop the timestamp column for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings['date'] = pd.to_datetime(df_ratings['timestamp'], unit='s').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.5 Get the average rating grouped by unique movies and store the array in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_score = df_ratings.groupby('movieId')['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   22998.00\n",
       "mean        3.53\n",
       "std         0.05\n",
       "min         3.34\n",
       "25%         3.50\n",
       "50%         3.53\n",
       "75%         3.57\n",
       "max         3.72\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_score.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.6 Make a new dataframe containing the average rating and the movie ID from the previous variable by resetting the index. This dataframe will be used later on to create a bigger dataframe with more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average_score = average_score.reset_index()[['movieId', 'rating']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Second group of datasets (information about movies on Amazon, Disney, Hulu and Netflix)._"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.7 Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_amazon.duplicated().sum())\n",
    "print(df_disney.duplicated().sum())\n",
    "print(df_hulu.duplicated().sum())\n",
    "print(df_netflix.duplicated().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.8 Make a list of the platforms dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platforms = [df_amazon, df_disney, df_hulu, df_netflix]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.9 Assing a name to these dataframes to create a composite ID later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon.name = 'amazon'\n",
    "df_disney.name = 'disney'\n",
    "df_hulu.name = 'hulu'\n",
    "df_netflix.name = 'netflix'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.10 Create a new column at the start of each of the platforms dataframes with the name 'id' and a value corresponding of the fist letter of the name of the platform and the show_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in platforms:\n",
    "    i['platform'] = i.name\n",
    "    i.insert(loc=0, column='id', value= i.name[0]+i['show_id'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.11 Merge the previous four dataframes into a new one provided that they already have an ID column and a platform column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms = pd.concat([df_amazon, df_disney, df_hulu, df_netflix])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.12 Check if the amount of unique movies in these platforms coincides with the amount of unique movies in the ratings data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ratings['movieId'].unique()) == len(df_platforms['id'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.13 Replace the null values in the rating column with the string \"G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms['rating'] = df_platforms['rating'].fillna(\"G\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.14 Remove empty spaces at the beggining of the string and then use the pandas to_datetime function to convert the original string into a proper date object format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms['date_added'] = df_platforms['date_added'].str.strip()\n",
    "df_platforms['date_added'] = pd.to_datetime(df_platforms['date_added'], format='%B %d, %Y')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.15 Go through every cell, select only the string type cells and apply the lower function to those, leave the rest as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms.iloc[:] = df_platforms.iloc[:].applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.16 Do the same for the ratings dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.iloc[:] = df_ratings.iloc[:].applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.17 I split the duration column into two new columns using the split method. Then I transform all the missing values in the duration_int column to 0 in order to be able to transform it into an integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_platforms[['duration_int', 'duration_type']] = df_platforms['duration'].str.split(expand=True)\n",
    "df_platforms['duration_int'] = df_platforms['duration_int'].fillna(0).astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.18 Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_average_score = df_average_score.rename(columns={'movieId':'id'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.19 Merge both dataframes on a common columnd 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = pd.merge(df_platforms, df_average_score, on='id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.20 Rename some more columns for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = df_score.rename(columns={'rating_x':'rating','rating_y':'score'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export transformed data to a new and clean dataset to be used in the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score.to_csv(\"data_api.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f89eb7ee7f691a835530315e9cc5d675e01c25354f3226d466fc4ec3dae4d41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
